{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5b9e585",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina' # For high-resolution.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydicom as dicom\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import torch \n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "# from torchsampler import ImbalancedDatasetSampler\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48bf28cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "## Hyperparameters\n",
    "USERNAME = os.getcwd().split('/')[2]\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "RESOLUTION = 512\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 4\n",
    "PIN_MEMORY = True\n",
    "DROP_LAST = True\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "THRESHOLD = 0.3\n",
    "# MIN_ACTIVATION_SIZE = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42f2a0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df(df_type):\n",
    "    #username = os.getcwd().split('/')[2]\n",
    "    df_path = '/home/{}/teams/dsc-180a---a14-[88137]/CANDID_PTX_csv/{}.csv'.format(USERNAME, df_type)\n",
    "    df = pd.read_csv(df_path)[['Mask_Path', 'XRay_Path', 'Intermediate_Predicted_Path']]\n",
    "#     df = pd.read_csv(df_path)[['Mask_Path', 'XRay_Path']]\n",
    "    df['Mask_Path'] = df['Mask_Path'].str.replace('anw008', USERNAME)\n",
    "    df['XRay_Path'] = df['XRay_Path'].str.replace('anw008', USERNAME)\n",
    "    df['Intermediate_Predicted_Path'] = df['Intermediate_Predicted_Path'].str.replace('anw008', USERNAME)\n",
    "    df['SOP'] = df['XRay_Path'].apply(lambda x: x.split('/')[-1])\n",
    "    \n",
    "    df['No_Pneumothorax'] = df['Mask_Path'].str.contains('negative_mask').astype(int)\n",
    "    df['Yes_Pneumothorax'] = 1 - df['No_Pneumothorax']\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0be5a495",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = read_df('train')\n",
    "val_df = read_df('validation')\n",
    "test_df = read_df('test')\n",
    "# left_df = read_df('unused_negative')\n",
    "pos_df = read_df('train_pos')\n",
    "neg_df = read_df('train_neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9d568df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mask_Path</th>\n",
       "      <th>XRay_Path</th>\n",
       "      <th>Intermediate_Predicted_Path</th>\n",
       "      <th>SOP</th>\n",
       "      <th>No_Pneumothorax</th>\n",
       "      <th>Yes_Pneumothorax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "      <td>0.0.00.400800.30.9.2.0.97200258210.26537585746...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "      <td>0.0.07.109556.72.6.9.7.18989625890.56335195975...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "      <td>0.0.08.203506.65.2.5.0.32924650882.36087017673...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "      <td>0.0.15.275672.29.0.5.8.45791925255.74232884473...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "      <td>0.0.155.605300.6.541.1.9531666121.6286372288.6...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Mask_Path  \\\n",
       "0  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...   \n",
       "1  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...   \n",
       "2  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...   \n",
       "3  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...   \n",
       "4  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...   \n",
       "\n",
       "                                           XRay_Path  \\\n",
       "0  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...   \n",
       "1  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...   \n",
       "2  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...   \n",
       "3  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...   \n",
       "4  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...   \n",
       "\n",
       "                         Intermediate_Predicted_Path  \\\n",
       "0  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...   \n",
       "1  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...   \n",
       "2  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...   \n",
       "3  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...   \n",
       "4  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...   \n",
       "\n",
       "                                                 SOP  No_Pneumothorax  \\\n",
       "0  0.0.00.400800.30.9.2.0.97200258210.26537585746...                0   \n",
       "1  0.0.07.109556.72.6.9.7.18989625890.56335195975...                0   \n",
       "2  0.0.08.203506.65.2.5.0.32924650882.36087017673...                0   \n",
       "3  0.0.15.275672.29.0.5.8.45791925255.74232884473...                0   \n",
       "4  0.0.155.605300.6.541.1.9531666121.6286372288.6...                0   \n",
       "\n",
       "   Yes_Pneumothorax  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd25c58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 5.0239])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_total = pos_df.shape[0]\n",
    "neg_total = neg_df.shape[0]\n",
    "\n",
    "def BCE_weight(num_pos, num_neg):\n",
    "    return torch.tensor([1, num_neg / num_pos])\n",
    "\n",
    "pos_weight_all = BCE_weight(pos_total, neg_total)\n",
    "pos_weight_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b94636bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'left_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_168/2626608222.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcombine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcombine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'left_df' is not defined"
     ]
    }
   ],
   "source": [
    "combine = pd.concat([train_df, left_df])\n",
    "combine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2fe5aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine['Intermediate_Predicted_Path'] = combine['XRay_Path'].str.replace('CANDID_PTX', 'CANDID_PTX_PREDS').apply(lambda x: x + '_predicted.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c4f9164",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = combine[combine['Yes_Pneumothorax'] == 1][['Mask_Path', 'XRay_Path', 'Intermediate_Predicted_Path']]\n",
    "neg_df = combine[combine['Yes_Pneumothorax'] == 0][['Mask_Path', 'XRay_Path', 'Intermediate_Predicted_Path']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8c20dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mask_Path</th>\n",
       "      <th>XRay_Path</th>\n",
       "      <th>Intermediate_Predicted_Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "      <td>/home/mel011/teams/dsc-180a---a14-[88137]/CAND...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Mask_Path  \\\n",
       "0  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...   \n",
       "1  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...   \n",
       "2  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...   \n",
       "3  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...   \n",
       "4  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...   \n",
       "\n",
       "                                           XRay_Path  \\\n",
       "0  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...   \n",
       "1  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...   \n",
       "2  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...   \n",
       "3  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...   \n",
       "4  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...   \n",
       "\n",
       "                         Intermediate_Predicted_Path  \n",
       "0  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...  \n",
       "1  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...  \n",
       "2  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...  \n",
       "3  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...  \n",
       "4  /home/mel011/teams/dsc-180a---a14-[88137]/CAND...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "428b4dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_df.to_csv('/home/{}/teams/dsc-180a---a14-[88137]/CANDID_PTX_csv/{}.csv'.format('mel011', 'train_pos'))\n",
    "# neg_df.to_csv('/home/{}/teams/dsc-180a---a14-[88137]/CANDID_PTX_csv/{}.csv'.format('mel011', 'train_neg'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b50959a",
   "metadata": {},
   "source": [
    "Finish creating new csv for imbalanced data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301761fb",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06d00843",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CANDID_PTX(Dataset):\n",
    "    def __init__(self, df, resolution, model_type):\n",
    "        self.img_paths = df['XRay_Path'].values\n",
    "        self.intermediate_paths = df['Intermediate_Predicted_Path'].values\n",
    "        self.mask_paths = df['Mask_Path'].values\n",
    "        self.labels = torch.tensor(df[['No_Pneumothorax', 'Yes_Pneumothorax']].values, dtype=torch.float32)\n",
    "        # Just changed by Angela\n",
    "        self.sop = df['SOP'].values\n",
    "        self.resolution = resolution\n",
    "        \n",
    "        # model_type: 'C' for Classification, 'S' for Segmentation, 'E' for Ensemble\n",
    "        self.model_type = model_type\n",
    "              \n",
    "        return\n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.img_paths.shape[0]\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.model_type == 'E':\n",
    "            # Designed for ensemble model's classification part\n",
    "            label = self.labels[idx]\n",
    "            \n",
    "            new_img_path = self.intermediate_paths[idx]\n",
    "            new_img = plt.imread(new_img_path)[:, :, :3]\n",
    "            to_tensor = transforms.ToTensor()\n",
    "            new_img = to_tensor(new_img)\n",
    "            \n",
    "            return new_img, label\n",
    "        \n",
    "        else:\n",
    "            img_path = self.img_paths[idx]\n",
    "            img = dicom.dcmread(img_path).pixel_array\n",
    "            img_min = np.min(img)\n",
    "            img_max = np.max(img)\n",
    "            img_norm = (img - img_min) / (img_max - img_min)\n",
    "            img_norm = cv2.resize(img_norm, (self.resolution, self.resolution))\n",
    "            img_norm = torch.tensor(img_norm).expand(3, self.resolution, self.resolution)\n",
    "\n",
    "            if self.model_type == 'C':\n",
    "                # Designed for classification model\n",
    "                label = self.labels[idx]\n",
    "\n",
    "                return img_norm, label\n",
    "\n",
    "            elif self.model_type == 'S':\n",
    "                # Designed for segmentaion models (might change later)\n",
    "                mask_path = self.mask_paths[idx]\n",
    "                mask = plt.imread(mask_path)[:, :, 0]\n",
    "                mask = cv2.resize(mask, (self.resolution, self.resolution))\n",
    "    #             mask = np.where(mask < 0.5, 0, 1)\n",
    "                mask = torch.tensor(mask).expand(1, self.resolution, self.resolution) \n",
    "        \n",
    "                sop = self.sop[idx]\n",
    "\n",
    "                return img_norm, mask, sop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50698c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loaders(model_type):\n",
    "    train_ds = CANDID_PTX(train_df, RESOLUTION, model_type)\n",
    "    val_ds = CANDID_PTX(val_df, RESOLUTION, model_type)\n",
    "    test_ds = CANDID_PTX(test_df, RESOLUTION, model_type)\n",
    "    \n",
    "    train_loader = DataLoader(train_ds, batch_size = BATCH_SIZE, num_workers = NUM_WORKERS, \n",
    "                          pin_memory = PIN_MEMORY, drop_last = DROP_LAST, shuffle = True)\n",
    "\n",
    "    val_loader = DataLoader(val_ds, batch_size = BATCH_SIZE, num_workers = NUM_WORKERS, \n",
    "                              pin_memory = PIN_MEMORY, drop_last = DROP_LAST, shuffle = False)\n",
    "\n",
    "    test_loader = DataLoader(test_ds, batch_size = BATCH_SIZE, num_workers = NUM_WORKERS, \n",
    "                              pin_memory = PIN_MEMORY, drop_last = DROP_LAST, shuffle = False)\n",
    "    \n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ae2bd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_loaders(num_neg, model_type):\n",
    "    cur_df = pd.concat([pos_df, neg_df.sample(n=num_neg, replace=False)]).sample(frac=1, ignore_index=True)\n",
    "    train_ds = CANDID_PTX(cur_df, RESOLUTION, model_type)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size = BATCH_SIZE, num_workers = NUM_WORKERS, \n",
    "                          pin_memory = PIN_MEMORY, drop_last = DROP_LAST, shuffle = True)\n",
    "\n",
    "    return train_loader, cur_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "600b73cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders_class = create_loaders('C')\n",
    "\n",
    "train_loaders_v1 = create_train_loaders(neg_df.shape[0], 'C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5eec8f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Test dataloader\n",
    "# sample_iter = iter(train_loaders_v1)\n",
    "# sample = next(sample_iter)\n",
    "# sample_2 = next(sample_iter)\n",
    "# print(\"--Check length of first batch, should be 3\")\n",
    "# print(len(sample))\n",
    "# print(\"--Check size of input images of first batch, should be ([{}, {}, {}, {}])\".format(BATCH_SIZE, 3, RESOLUTION, RESOLUTION))\n",
    "# print(sample[0].size())\n",
    "# print(sample[0][0])\n",
    "# print(\"--Check size of labels/masks of first batch\")\n",
    "# print(sample[1].size())\n",
    "# print(sample[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b6b9592",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modifying model\n",
    "class resnet34(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Best to use pre-trained\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = models.resnet34(pretrained=True)\n",
    "\n",
    "        layers = np.array([layer for layer in self.model.children()])\n",
    "        \n",
    "        for layer in layers[:-2]:\n",
    "\n",
    "            for param in layer.parameters():\n",
    "                \n",
    "                # Change parameters for all layers\n",
    "                param.requires_grad = False\n",
    "                \n",
    "        self.model.fc = nn.Linear(512, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.model(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf1383b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_class(model, num_epochs, batch_size, learning_rate, \n",
    "                    train_loader, val_loader):\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    all_train_loss = []\n",
    "    all_val_loss = []\n",
    "#     all_preds = []\n",
    "#     all_masks = []\n",
    "#     all_xray = []\n",
    "    \n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    pos_weight_all.to(DEVICE)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss(pos_weight = pos_weight_all)#.to(DEVICE)\n",
    "#     loss_fn = torch.nn.BCEWithLogitsLoss()#.to(DEVICE)\n",
    "\n",
    "    \n",
    "#     scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    pos_num = pos_df.shape[0]\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        total_train_loss = 0\n",
    "        batch_num = 0\n",
    "        model.train()\n",
    "        \n",
    "        if epoch == 3:\n",
    "            train_loader, cur_num = create_train_loaders(neg_df.shape[0], 'C')\n",
    "            print('current number of training set is: {}'.format(cur_num))\n",
    "\n",
    "        \n",
    "        if epoch == 6:\n",
    "            train_loader, cur_num = create_train_loaders(neg_df.shape[0], 'C')\n",
    "            print('current number of training set is: {}'.format(cur_num))\n",
    "        \n",
    "        if epoch == 9:\n",
    "            train_loader, cur_num = create_train_loaders(neg_df.shape[0], 'C')\n",
    "            print('current number of training set is: {}'.format(cur_num))\n",
    "        \n",
    "        if epoch == 12:\n",
    "            train_loader, cur_num = create_train_loaders(neg_df.shape[0], 'C')\n",
    "            print('current number of training set is: {}'.format(cur_num))\n",
    "        \n",
    "        for i, (imgs, labels) in enumerate(train_loader):\n",
    "            batch_num += 1\n",
    "            \n",
    "            imgs, labels = imgs.to(DEVICE, dtype=torch.float), labels.to(DEVICE, dtype=torch.float)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            preds = model(imgs)\n",
    "            \n",
    "            \n",
    "            if (i == 0) & (epoch == 0):\n",
    "                print(preds)\n",
    "                print(labels)\n",
    "\n",
    "            \n",
    "            loss = loss_fn(preds, labels)\n",
    "    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += float(loss)\n",
    "            \n",
    "            \n",
    "        if epoch % 3 == 0:\n",
    "            print(\"Total # of training batch: \", i + 1)\n",
    "\n",
    "        all_train_loss.append(total_train_loss / batch_num)\n",
    "            \n",
    "            \n",
    "    ## validation set\n",
    "        batch_num = 0\n",
    "        total_val_loss = 0\n",
    "        model.eval()\n",
    "#         print(\"LET'S START VALIDATION!!!\")\n",
    "        for i, (imgs, labels) in enumerate(val_loader):\n",
    "            batch_num += 1\n",
    "            \n",
    "            imgs, labels = imgs.to(DEVICE, dtype=torch.float), labels.to(DEVICE, dtype=torch.float)\n",
    "            \n",
    "            preds = model(imgs)\n",
    "            \n",
    "            loss = loss_fn(preds, labels) # is this mean or sum?\n",
    "\n",
    "            total_val_loss += float(loss) # accumulate the total loss for this epoch.\n",
    "            \n",
    "#             if i == 1:\n",
    "#                 all_preds.append(preds.detach().cpu())\n",
    "#                 all_masks.append(masks.detach().cpu())\n",
    "#                 all_xray.append(imgs.detach().cpu())\n",
    "            \n",
    "        if epoch == 0:\n",
    "            print(\"Total # of validation batch: \", i + 1)\n",
    "\n",
    "        all_val_loss.append(total_val_loss / batch_num)\n",
    "        \n",
    "    \n",
    "    #plot_both_loss(all_train_loss, all_val_loss)\n",
    "        \n",
    "    return model, all_train_loss, all_val_loss#, all_preds, all_masks, all_xray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55908549",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = resnet34()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a55686a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'pos_weight_all' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_796/1435713420.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m resnet_model, train_loss, val_loss = training_class(model = model_class,\n\u001b[0m\u001b[1;32m      2\u001b[0m                                             \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                             \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                             train_loader = train_loaders_v1[0], val_loader = loaders_class[1])\n",
      "\u001b[0;32m/tmp/ipykernel_796/2288401905.py\u001b[0m in \u001b[0;36mtraining_class\u001b[0;34m(model, num_epochs, batch_size, learning_rate, train_loader, val_loader)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mpos_weight_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_weight_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCEWithLogitsLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos_weight_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.to(DEVICE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#     loss_fn = torch.nn.BCEWithLogitsLoss()#.to(DEVICE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'pos_weight_all' referenced before assignment"
     ]
    }
   ],
   "source": [
    "resnet_model, train_loss, val_loss = training_class(model = model_class,\n",
    "                                            num_epochs = 15, batch_size = BATCH_SIZE,\n",
    "                                            learning_rate = LEARNING_RATE,\n",
    "                                            train_loader = train_loaders_v1[0], val_loader = loaders_class[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a7dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_both_loss(all_train_loss, all_val_loss, model_name, resolution):\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    epoch_num = len(all_train_loss)\n",
    "    df = pd.DataFrame({'x':range(epoch_num),\n",
    "                    'train_loss':all_train_loss,\n",
    "                      'val_loss':all_val_loss})\n",
    "    df = df.set_index('x')\n",
    "    \n",
    "    train_val_loss = sns.lineplot(data=df, linewidth=2.5)\n",
    "\n",
    "    ## now label the y- and x-axes.\n",
    "    plt.ylabel('BCE Loss')\n",
    "    plt.xlabel('Epoch Number')\n",
    "    plt.title('BCE Loss of {} with resolution {}'.format(model_name, resolution))\n",
    "    plt.show()\n",
    "    \n",
    "    fig = train_val_loss.get_figure()\n",
    "    #fig.save('train_val_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1ff8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_both_loss(train_loss, val_loss, \"ResNet34 with Imbalanced Training Data\", str(RESOLUTION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a7d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, y_true, model_name, resolution):\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_test)\n",
    "\n",
    "    sns.heatmap(cm, annot=True, cmap = 'Blues', fmt=\"d\")\n",
    "    plt.title('Confusion matrix of model {} with resolution {}'.format(model_name, resolution))\n",
    "    plt.xlabel('Prediction')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea5bb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_test, y_true, model_name, resolution):\n",
    "    fpr, tpr, threshold = roc_curve(y_true, y_test, drop_intermediate = False)\n",
    "    roc_auc = roc_auc_score(y_true, y_test)\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.plot([0, 1], [0, 1])\n",
    "    plt.plot(fpr, tpr, label='{}(area = {:.3f})'.format(model_name, roc_auc))\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.title('ROC curve of model {} with resolution {}'.format(model_name, resolution))\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43cb1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_metrics(test_loader, model, model_name, resolution):\n",
    "    \"\"\"\n",
    "    Calculate confusion matrix & auc-roc\n",
    "    Return a list \n",
    "    \"\"\"\n",
    "    y_test = np.array([])\n",
    "    y_true = np.array([])\n",
    "    y_test_prob = np.array([])\n",
    "    total_num_batch = 0\n",
    "    for i, (imgs, labels) in enumerate(test_loader):\n",
    "        total_num_batch += 1\n",
    "        imgs, labels = imgs.to(DEVICE, dtype=torch.float), labels.to(DEVICE, dtype=torch.float)\n",
    "        preds = model(imgs)\n",
    "        \n",
    "        soft_max = nn.Softmax(dim=1)\n",
    "        pred_prob = soft_max(preds).detach().cpu().numpy()\n",
    "        \n",
    "        pred_label = np.argmax(pred_prob, axis=1)\n",
    "        true_label = labels.detach().cpu().numpy().astype(int)[:, 1]\n",
    "        \n",
    "        y_test = np.concatenate((y_test, pred_label))\n",
    "        y_true = np.concatenate((y_true, true_label))\n",
    "\n",
    "        # add this line\n",
    "        y_test_prob = np.concatenate((y_test_prob, pred_prob[:, 1]))\n",
    "        # if the auc-roc curve still only have one point, chance the above line to this one\n",
    "        # bug-free not guaranteed\n",
    "#         y_test_prob = np.concatenate((y_test_prob, np.max(preds, axis = 1)))\n",
    "\n",
    "    \n",
    "    \n",
    "    plot_confusion_matrix(y_test, y_true, model_name, str(resolution))\n",
    "    print(\"The F1-Score is: {}\".format(f1_score(y_true, y_test)))\n",
    "    # modify this line, change from y_test to y_test_prob\n",
    "    plot_roc_curve(y_test_prob, y_true, model_name, str(resolution))\n",
    "    \n",
    "    print('Total Number of Batch Size: ', total_num_batch)\n",
    "    return y_test, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca799db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test, y_true = test_metrics(loaders_class[2], resnet_model, 'ResNet_Model', str(RESOLUTION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c601ac3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
