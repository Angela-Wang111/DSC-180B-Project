{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "111bb615",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'retina' # For high-resolution.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pydicom as dicom\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import torch \n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "import cv2\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bce510ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "## Hyperparameters\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "RESOLUTION = 256\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 4\n",
    "PIN_MEMORY = True\n",
    "DROP_LAST = True\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 3\n",
    "\n",
    "THRESHOLD = 0.3\n",
    "# MIN_ACTIVATION_SIZE = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61aec0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_df(df_type):\n",
    "    username = os.getcwd().split('/')[2]\n",
    "    df_path = '/home/{}/teams/dsc-180a---a14-[88137]/CANDID_PTX_csv/{}.csv'.format(username, df_type)\n",
    "    df = pd.read_csv(df_path)[['Mask_Path', 'XRay_Path']]\n",
    "    df['Mask_Path'] = df['Mask_Path'].str.replace('anw008', username)\n",
    "    df['XRay_Path'] = df['XRay_Path'].str.replace('anw008', username)\n",
    "    df['No_Pneumothorax'] = df['Mask_Path'].str.contains('negative_mask').astype(int)\n",
    "    df['Yes_Pneumothorax'] = 1 - df['No_Pneumothorax']\n",
    "    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f2c008d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = read_df('train')\n",
    "val_df = read_df('validation')\n",
    "test_df = read_df('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85a57e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CANDID_PTX(Dataset):\n",
    "    def __init__(self, df, resolution, model_type):\n",
    "        self.img_paths = df['XRay_Path'].values\n",
    "        self.mask_paths = df['Mask_Path'].values\n",
    "        self.labels = torch.tensor(df[['Yes_Pneumothorax', 'No_Pneumothorax']].values, dtype=torch.float32)\n",
    "    \n",
    "        self.resolution = resolution\n",
    "        \n",
    "        # model_type: 'C' for Classification, 'S' for Segmentation\n",
    "        self.model_type = model_type\n",
    "          \n",
    "        return\n",
    "            \n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.img_paths.shape[0]\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.img_paths[idx]\n",
    "        img = dicom.dcmread(img_path).pixel_array\n",
    "        img_min = np.min(img)\n",
    "        img_max = np.max(img)\n",
    "        img_norm = (img - img_min) / (img_max - img_min)\n",
    "        img_norm = cv2.resize(img_norm, (self.resolution, self.resolution))\n",
    "        img_norm = torch.tensor(img_norm).expand(3, self.resolution, self.resolution)\n",
    "        \n",
    "        if self.model_type == 'C':\n",
    "            label = self.labels[idx]\n",
    "            \n",
    "            return img_norm, label\n",
    "        \n",
    "        elif self.model_type == 'S':\n",
    "            mask_path = self.mask_paths[idx]\n",
    "            mask = plt.imread(mask_path)[:, :, 0]\n",
    "            mask = cv2.resize(mask, (self.resolution, self.resolution))\n",
    "            mask = torch.tensor(mask).expand(1, self.resolution, self.resolution) \n",
    "\n",
    "            return img_norm, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f18d7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Dataset\n",
    "train_ds = CANDID_PTX(train_df, RESOLUTION, 'C')\n",
    "val_ds = CANDID_PTX(val_df, RESOLUTION, 'C')\n",
    "test_ds = CANDID_PTX(test_df, RESOLUTION, 'C')\n",
    "\n",
    "### Create Dataloader\n",
    "train_loader = DataLoader(train_ds, batch_size = BATCH_SIZE, num_workers = NUM_WORKERS, \n",
    "                          pin_memory = PIN_MEMORY, drop_last = DROP_LAST, shuffle = True)\n",
    "\n",
    "val_loader = DataLoader(val_ds, batch_size = BATCH_SIZE, num_workers = NUM_WORKERS, \n",
    "                          pin_memory = PIN_MEMORY, drop_last = DROP_LAST, shuffle = False)\n",
    "\n",
    "test_loader = DataLoader(test_ds, batch_size = BATCH_SIZE, num_workers = NUM_WORKERS, \n",
    "                          pin_memory = PIN_MEMORY, drop_last = DROP_LAST, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0c5a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Test dataloader\n",
    "# sample = next(iter(val_loader))\n",
    "# print(\"--Check length of first batch, should be 2\")\n",
    "# print(len(sample))\n",
    "# print(\"--Check size of input images of first batch, should be ([{}, {}, {}, {}])\".format(BATCH_SIZE, 3, RESOLUTION, RESOLUTION))\n",
    "# print(sample[0].size())\n",
    "# print(sample[0][0])\n",
    "# print(\"--Check size of labels/masks of first batch\")\n",
    "# print(sample[1].size())\n",
    "# print(sample[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff157608",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71a64dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.Unet(\"resnet34\", encoder_weights=\"imagenet\", in_channels = 3, classes=1, activation=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a625386d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modifying model\n",
    "class resnet34(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Best to use pre-trained\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = models.resnet34(pretrained=True)\n",
    "\n",
    "        # initialize new output layer\n",
    "\n",
    "#         layers = np.array([layer for layer in self.model.children()])\n",
    "\n",
    "#         for layer in layers[:-4]:\n",
    "\n",
    "#             for param in layer.parameters():\n",
    "                \n",
    "#                 # Change parameters for all layers\n",
    "#                 param.requires_grad = False\n",
    "        \n",
    "#         for layer in layers[-4][:-4]:\n",
    "#             for param in layer.parameters():\n",
    "#                 param.requires_grad = False\n",
    "        \n",
    "        layers = np.array([layer for layer in self.model.children()])\n",
    "        \n",
    "        for layer in layers[:-2]:\n",
    "\n",
    "            for param in layer.parameters():\n",
    "                \n",
    "                # Change parameters for all layers\n",
    "                param.requires_grad = False\n",
    "                \n",
    "        self.model.fc = nn.Linear(512, 2)\n",
    "        \n",
    "        #num_open_param = 0\n",
    "        \n",
    "#         for layer in layers[-3:]:\n",
    "#             for param in layer.parameters():\n",
    "#                 num_open_param += 1\n",
    "#         print('Num Open Parameters: ', num_open_param)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.model(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2607b0",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61398ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_seg(model, num_epochs, batch_size, learning_rate, \n",
    "                    train_loader, val_loader):\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    all_train_loss = []\n",
    "    all_val_loss = []\n",
    "    all_preds = []\n",
    "    all_masks = []\n",
    "    all_xray = []\n",
    "    \n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        total_train_loss = 0\n",
    "        batch_num = 0\n",
    "        model.train()\n",
    "        \n",
    "        for i, (imgs, masks) in enumerate(train_loader):\n",
    "            batch_num += 1\n",
    "            \n",
    "            imgs, masks = imgs.to(DEVICE, dtype=torch.float), masks.to(DEVICE, dtype=torch.float)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            preds = model(imgs)\n",
    "            \n",
    "            \n",
    "            if (i == 0) & (epoch == 0):\n",
    "                print(preds)\n",
    "#             print(preds.size())\n",
    "#             print(masks.size())\n",
    "\n",
    "            \n",
    "            loss = loss_fn(preds, masks)\n",
    "    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "#             with torch.cuda.amp.autocast():\n",
    "#                 preds = model(imgs)\n",
    "#                 if i == 0:\n",
    "#                     all_preds.append(preds.detach().cpu())\n",
    "#                 loss = loss_fn(preds, masks)\n",
    "                        \n",
    "#             optimizer.zero_grad()\n",
    "#             scaler.scale(loss).backward()\n",
    "#             scaler.step(optimizer)\n",
    "#             scaler.update()\n",
    "            \n",
    "            total_train_loss += float(loss)\n",
    "            \n",
    "            \n",
    "        if epoch == 0:\n",
    "            print(\"Total # of training batch: \", i + 1)\n",
    "\n",
    "        all_train_loss.append(total_train_loss / batch_num)\n",
    "            \n",
    "            \n",
    "    ## validation set\n",
    "        batch_num = 0\n",
    "        total_val_loss = 0\n",
    "        model.eval()\n",
    "        \n",
    "        for i, (imgs, masks) in enumerate(val_loader):\n",
    "            batch_num += 1\n",
    "            \n",
    "            imgs, masks = imgs.to(DEVICE, dtype=torch.float), masks.to(DEVICE, dtype=torch.float)\n",
    "            \n",
    "            preds = model(imgs)\n",
    "            \n",
    "            loss = loss_fn(preds, masks) # is this mean or sum?\n",
    "\n",
    "            total_val_loss += float(loss) # accumulate the total loss for this epoch.\n",
    "            \n",
    "            if i == 1:\n",
    "                all_preds.append(preds.detach().cpu())\n",
    "                all_masks.append(masks.detach().cpu())\n",
    "                all_xray.append(imgs.detach().cpu())\n",
    "            \n",
    "        if epoch == 0:\n",
    "            print(\"Total # of validation batch: \", i + 1)\n",
    "\n",
    "        all_val_loss.append(total_val_loss / batch_num)\n",
    "        \n",
    "    \n",
    "    #plot_both_loss(all_train_loss, all_val_loss)\n",
    "        \n",
    "    return model, all_train_loss, all_val_loss, all_preds, all_masks, all_xray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1535b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model, train_loss, val_loss, logit_mask, true_mask, ori_xray = training_seg(model = model,\n",
    "                                            num_epochs = NUM_EPOCHS, batch_size = BATCH_SIZE,\n",
    "                                            learning_rate = LEARNING_RATE,\n",
    "                                            train_loader = train_loader, val_loader = val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30fc4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_class(model, num_epochs, batch_size, learning_rate, \n",
    "                    train_loader, val_loader):\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    all_train_loss = []\n",
    "    all_val_loss = []\n",
    "#     all_preds = []\n",
    "#     all_masks = []\n",
    "#     all_xray = []\n",
    "    \n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        total_train_loss = 0\n",
    "        batch_num = 0\n",
    "        model.train()\n",
    "        \n",
    "        for i, (imgs, labels) in enumerate(train_loader):\n",
    "            batch_num += 1\n",
    "            \n",
    "            imgs, labels = imgs.to(DEVICE, dtype=torch.float), labels.to(DEVICE, dtype=torch.float)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            preds = model(imgs)\n",
    "            \n",
    "            \n",
    "            if (i == 0) & (epoch == 0):\n",
    "                print(preds)\n",
    "                print(labels)\n",
    "#             print(preds.size())\n",
    "#             print(masks.size())\n",
    "\n",
    "            \n",
    "            loss = loss_fn(preds, labels)\n",
    "    \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "#             with torch.cuda.amp.autocast():\n",
    "#                 preds = model(imgs)\n",
    "#                 if i == 0:\n",
    "#                     all_preds.append(preds.detach().cpu())\n",
    "#                 loss = loss_fn(preds, masks)\n",
    "                        \n",
    "#             optimizer.zero_grad()\n",
    "#             scaler.scale(loss).backward()\n",
    "#             scaler.step(optimizer)\n",
    "#             scaler.update()\n",
    "            \n",
    "            total_train_loss += float(loss)\n",
    "            \n",
    "            \n",
    "        if epoch == 0:\n",
    "            print(\"Total # of training batch: \", i + 1)\n",
    "\n",
    "        all_train_loss.append(total_train_loss / batch_num)\n",
    "            \n",
    "            \n",
    "    ## validation set\n",
    "        batch_num = 0\n",
    "        total_val_loss = 0\n",
    "        model.eval()\n",
    "        \n",
    "        for i, (imgs, labels) in enumerate(val_loader):\n",
    "            batch_num += 1\n",
    "            \n",
    "            imgs, labels = imgs.to(DEVICE, dtype=torch.float), labels.to(DEVICE, dtype=torch.float)\n",
    "            \n",
    "            preds = model(imgs)\n",
    "            \n",
    "            loss = loss_fn(preds, labels) # is this mean or sum?\n",
    "\n",
    "            total_val_loss += float(loss) # accumulate the total loss for this epoch.\n",
    "            \n",
    "#             if i == 1:\n",
    "#                 all_preds.append(preds.detach().cpu())\n",
    "#                 all_masks.append(masks.detach().cpu())\n",
    "#                 all_xray.append(imgs.detach().cpu())\n",
    "            \n",
    "        if epoch == 0:\n",
    "            print(\"Total # of validation batch: \", i + 1)\n",
    "\n",
    "        all_val_loss.append(total_val_loss / batch_num)\n",
    "        \n",
    "    \n",
    "    #plot_both_loss(all_train_loss, all_val_loss)\n",
    "        \n",
    "    return model, all_train_loss, all_val_loss#, all_preds, all_masks, all_xray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb53a98d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
